{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 1 Letter S Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters[18,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "newLetter=[19.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "        1.,  1.,  1.,  1.,  0,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
    "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
    "        0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "        0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "        0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "        1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
    "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look to perform all filtrations on the new letter, as well as the density tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Putts\\Anaconda3\\lib\\site-packages\\ripser\\ripser.py:342: RuntimeWarning: invalid value encountered in maximum\n",
      "  thisD = np.maximum(thisD, tD)\n"
     ]
    }
   ],
   "source": [
    " #Left to Right Filtration\n",
    "letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "for k in range(1,101):\n",
    "    if newLetter[k]==1.0:\n",
    "        row=int((k-1)/10) \n",
    "        column=(k-1)%10 \n",
    "        letter[row,column]=k%10            \n",
    "dgmNLR = lower_star_img(letter)\n",
    "\n",
    " # Right to Left Filtration\n",
    "letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "for k in range(1,101):\n",
    "    if newLetter[k]==1.0:\n",
    "        row=int((k-1)/10) \n",
    "        column=(k-1)%10 \n",
    "        letter[row,column]=10-k%10            \n",
    "dgmNRL = lower_star_img(letter)\n",
    "    \n",
    " # Angle Filtration\n",
    "letter=np.full((10, 10), 100)\n",
    "\n",
    "# convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "for k in range(1,101):\n",
    "    if newLetter[k]==1.0:\n",
    "        row=int((k-1)/10) \n",
    "        column=(k-1)%10 \n",
    "        letter[row,column]=max(k%10,int(k-1)%10)            \n",
    "dgmNA = lower_star_img(letter)\n",
    "    \n",
    " # Diagonal Filtration\n",
    "letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "for k in range(1,101):\n",
    "    if newLetter[k]==1.0:\n",
    "        row=int((k-1)/10) \n",
    "        column=(k-1)%10 \n",
    "        letter[row,column]=(column+row)*k%10            \n",
    "dgmND = lower_star_img(letter)\n",
    "\n",
    "# A test to differentiate some letters\n",
    "\n",
    "bottom_test=sum(newLetter[51:101])\n",
    "    \n",
    "\n",
    "right_test=sum(np.concatenate((newLetter[6:11],\n",
    "              newLetter[16:21],\n",
    "              newLetter[26:31],\n",
    "              newLetter[36:41],\n",
    "              newLetter[46:51],\n",
    "              newLetter[56:61],\n",
    "              newLetter[66:71],\n",
    "              newLetter[76:81],\n",
    "              newLetter[86:91],\n",
    "              newLetter[96:101]\n",
    "              )))\n",
    "\n",
    "botright = sum(np.concatenate((\n",
    "              newLetter[56:61],\n",
    "              newLetter[66:71],\n",
    "              newLetter[76:81],\n",
    "              newLetter[86:91],\n",
    "              newLetter[96:101]\n",
    "              )))\n",
    "\n",
    "top_test = sum(newLetter[1:51])\n",
    "\n",
    "density_test = sum(newLetter[1:101])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the filtrations to find the bottleneck distance between the new letter and all of the old ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change infinities to very large numbers\n",
    "dgmNLR[np.isinf(dgmNLR)] = 10000\n",
    "dgmNRL[np.isinf(dgmNRL)] = 10000\n",
    "dgmNA[np.isinf(dgmNA)] = 10000\n",
    "dgmND[np.isinf(dgmND)] = 10000\n",
    "\n",
    "# Find bottleneck distance between new letter and previous letters\n",
    "\n",
    "# Left to Right\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "BNDNLR = [None]*26\n",
    "for i in range(26):\n",
    "    BNDNLR[i] = pm.bottleneck(dgmLR[i],dgmNLR)\n",
    "BNDNLR = np.array(BNDNLR)\n",
    "BNDNLR[BNDNLR>1000]=0\n",
    "\n",
    "# Right to Left\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "BNDNRL = [None]*26\n",
    "for i in range(26):\n",
    "    BNDNRL[i] = pm.bottleneck(dgmRL[i],dgmNRL)\n",
    "BNDNRL = np.array(BNDNRL) \n",
    "BNDNRL[BNDNRL>1000]=0\n",
    "\n",
    "# Angle\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "BNDNA = [None]*26\n",
    "for i in range(26):\n",
    "    BNDNA[i] = pm.bottleneck(dgmAngle[i],dgmNA)\n",
    "BNDNA = np.array(BNDNA)\n",
    "BNDNA[BNDNA>1000]=0\n",
    "    \n",
    "# Diagonoal\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "BNDND = [None]*26\n",
    "for i in range(26):\n",
    "    BNDND[i] = pm.bottleneck(dgmDiagonal[i],dgmND)\n",
    "BNDND = np.array(BNDND)\n",
    "BNDND[BNDND>1000]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert them into their values using Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left to Right Value\n",
    "temp=np.vstack((BNDLR,BNDNLR))\n",
    "temp2=np.append(BNDNLR,0)\n",
    "NewBNDLR = np.hstack((temp, np.atleast_2d(temp2).T))\n",
    "LRClust = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(NewBNDLR)\n",
    "LRValue=LRClust.labels_[26]\n",
    "\n",
    "# Right to Left Value\n",
    "temp=np.vstack((BNDRL,BNDNRL))\n",
    "temp2=np.append(BNDNRL,0)\n",
    "NewBNDRL = np.hstack((temp, np.atleast_2d(temp2).T))\n",
    "RLClust = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(NewBNDRL)\n",
    "RLValue=RLClust.labels_[26]\n",
    "\n",
    "\n",
    "# Angle Value\n",
    "temp=np.vstack((BNDAngle,BNDNA))\n",
    "temp2=np.append(BNDNA,0)\n",
    "NewBNDA = np.hstack((temp, np.atleast_2d(temp2).T))\n",
    "AngleClust = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(NewBNDA)\n",
    "AValue=AngleClust.labels_[26]\n",
    "\n",
    "\n",
    "# Diagonal Value\n",
    "temp=np.vstack((BNDDiagonal,BNDND))\n",
    "temp2=np.append(BNDND,0)\n",
    "NewBNDD = np.hstack((temp, np.atleast_2d(temp2).T))\n",
    "DiagonalClust = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(NewBNDD)\n",
    "DValue=DiagonalClust.labels_[26]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine these values into one vector and run our model on that vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_Letter = np.array((LRValue,\n",
    "                             RLValue,\n",
    "                             AValue,\n",
    "                             DValue,\n",
    "                             bottom_test,\n",
    "                             right_test,\n",
    "                             botright,\n",
    "                             top_test,\n",
    "                             density_test))\n",
    "LogReg.predict(New_Letter.reshape(1,-1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slightly sparse S is classified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 2: P Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,\n",
       "        0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters[15,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "newLetter=[16.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "        1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
    "        0.,  1.,  1.,  0.,  0.,  0.,  0.,  0,  0.,  0.,  0.,  1.,  1.,\n",
    "        0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
    "        0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
    "        0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look to perform all filtrations on the new letter, as well as the density tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Putts\\Anaconda3\\lib\\site-packages\\ripser\\ripser.py:342: RuntimeWarning: invalid value encountered in maximum\n",
      "  thisD = np.maximum(thisD, tD)\n"
     ]
    }
   ],
   "source": [
    " #Left to Right Filtration\n",
    "letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "for k in range(1,101):\n",
    "    if newLetter[k]==1.0:\n",
    "        row=int((k-1)/10) \n",
    "        column=(k-1)%10 \n",
    "        letter[row,column]=k%10            \n",
    "dgmNLR = lower_star_img(letter)\n",
    "\n",
    " # Right to Left Filtration\n",
    "letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "for k in range(1,101):\n",
    "    if newLetter[k]==1.0:\n",
    "        row=int((k-1)/10) \n",
    "        column=(k-1)%10 \n",
    "        letter[row,column]=10-k%10            \n",
    "dgmNRL = lower_star_img(letter)\n",
    "    \n",
    " # Angle Filtration\n",
    "letter=np.full((10, 10), 100)\n",
    "\n",
    "# convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "for k in range(1,101):\n",
    "    if newLetter[k]==1.0:\n",
    "        row=int((k-1)/10) \n",
    "        column=(k-1)%10 \n",
    "        letter[row,column]=max(k%10,int(k-1)%10)            \n",
    "dgmNA = lower_star_img(letter)\n",
    "    \n",
    " # Diagonal Filtration\n",
    "letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "for k in range(1,101):\n",
    "    if newLetter[k]==1.0:\n",
    "        row=int((k-1)/10) \n",
    "        column=(k-1)%10 \n",
    "        letter[row,column]=(column+row)*k%10            \n",
    "dgmND = lower_star_img(letter)\n",
    "\n",
    "# A test to differentiate some letters\n",
    "\n",
    "bottom_test=sum(newLetter[51:101])\n",
    "    \n",
    "\n",
    "right_test=sum(np.concatenate((newLetter[6:11],\n",
    "              newLetter[16:21],\n",
    "              newLetter[26:31],\n",
    "              newLetter[36:41],\n",
    "              newLetter[46:51],\n",
    "              newLetter[56:61],\n",
    "              newLetter[66:71],\n",
    "              newLetter[76:81],\n",
    "              newLetter[86:91],\n",
    "              newLetter[96:101]\n",
    "              )))\n",
    "\n",
    "botright = sum(np.concatenate((\n",
    "              newLetter[56:61],\n",
    "              newLetter[66:71],\n",
    "              newLetter[76:81],\n",
    "              newLetter[86:91],\n",
    "              newLetter[96:101]\n",
    "              )))\n",
    "\n",
    "top_test = sum(newLetter[1:51])\n",
    "\n",
    "density_test = sum(newLetter[1:101])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the filtrations to find the bottleneck distance between the new letter and all of the old ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change infinities to very large numbers\n",
    "dgmNLR[np.isinf(dgmNLR)] = 10000\n",
    "dgmNRL[np.isinf(dgmNRL)] = 10000\n",
    "dgmNA[np.isinf(dgmNA)] = 10000\n",
    "dgmND[np.isinf(dgmND)] = 10000\n",
    "\n",
    "# Find bottleneck distance between new letter and previous letters\n",
    "\n",
    "# Left to Right\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "BNDNLR = [None]*26\n",
    "for i in range(26):\n",
    "    BNDNLR[i] = pm.bottleneck(dgmLR[i],dgmNLR)\n",
    "BNDNLR = np.array(BNDNLR)\n",
    "BNDNLR[BNDNLR>1000]=0\n",
    "\n",
    "# Right to Left\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "BNDNRL = [None]*26\n",
    "for i in range(26):\n",
    "    BNDNRL[i] = pm.bottleneck(dgmRL[i],dgmNRL)\n",
    "BNDNRL = np.array(BNDNRL) \n",
    "BNDNRL[BNDNRL>1000]=0\n",
    "\n",
    "# Angle\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "BNDNA = [None]*26\n",
    "for i in range(26):\n",
    "    BNDNA[i] = pm.bottleneck(dgmAngle[i],dgmNA)\n",
    "BNDNA = np.array(BNDNA)\n",
    "BNDNA[BNDNA>1000]=0\n",
    "    \n",
    "# Diagonoal\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "BNDND = [None]*26\n",
    "for i in range(26):\n",
    "    BNDND[i] = pm.bottleneck(dgmDiagonal[i],dgmND)\n",
    "BNDND = np.array(BNDND)\n",
    "BNDND[BNDND>1000]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert them into their values using Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left to Right Value\n",
    "temp=np.vstack((BNDLR,BNDNLR))\n",
    "temp2=np.append(BNDNLR,0)\n",
    "NewBNDLR = np.hstack((temp, np.atleast_2d(temp2).T))\n",
    "LRClust = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(NewBNDLR)\n",
    "LRValue=LRClust.labels_[26]\n",
    "\n",
    "# Right to Left Value\n",
    "temp=np.vstack((BNDRL,BNDNRL))\n",
    "temp2=np.append(BNDNRL,0)\n",
    "NewBNDRL = np.hstack((temp, np.atleast_2d(temp2).T))\n",
    "RLClust = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(NewBNDRL)\n",
    "RLValue=RLClust.labels_[26]\n",
    "\n",
    "\n",
    "# Angle Value\n",
    "temp=np.vstack((BNDAngle,BNDNA))\n",
    "temp2=np.append(BNDNA,0)\n",
    "NewBNDA = np.hstack((temp, np.atleast_2d(temp2).T))\n",
    "AngleClust = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(NewBNDA)\n",
    "AValue=AngleClust.labels_[26]\n",
    "\n",
    "\n",
    "# Diagonal Value\n",
    "temp=np.vstack((BNDDiagonal,BNDND))\n",
    "temp2=np.append(BNDND,0)\n",
    "NewBNDD = np.hstack((temp, np.atleast_2d(temp2).T))\n",
    "DiagonalClust = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(NewBNDD)\n",
    "DValue=DiagonalClust.labels_[26]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine these values into one vector and run our model on that vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_Letter = np.array((LRValue,\n",
    "                             RLValue,\n",
    "                             AValue,\n",
    "                             DValue,\n",
    "                             bottom_test,\n",
    "                             right_test,\n",
    "                             botright,\n",
    "                             top_test,\n",
    "                             density_test))\n",
    "LogReg.predict(New_Letter.reshape(1,-1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The P is classified correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 3: Sparse Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,\n",
       "        1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters[16,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "newLetter=[17.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "        1.,  1.,  0,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
    "        0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
    "        0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
    "        1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
    "        0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,\n",
    "        1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
    "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look to perform all filtrations on the new letter, as well as the density tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Putts\\Anaconda3\\lib\\site-packages\\ripser\\ripser.py:342: RuntimeWarning: invalid value encountered in maximum\n",
      "  thisD = np.maximum(thisD, tD)\n"
     ]
    }
   ],
   "source": [
    " #Left to Right Filtration\n",
    "letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "for k in range(1,101):\n",
    "    if newLetter[k]==1.0:\n",
    "        row=int((k-1)/10) \n",
    "        column=(k-1)%10 \n",
    "        letter[row,column]=k%10            \n",
    "dgmNLR = lower_star_img(letter)\n",
    "\n",
    " # Right to Left Filtration\n",
    "letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "for k in range(1,101):\n",
    "    if newLetter[k]==1.0:\n",
    "        row=int((k-1)/10) \n",
    "        column=(k-1)%10 \n",
    "        letter[row,column]=10-k%10            \n",
    "dgmNRL = lower_star_img(letter)\n",
    "    \n",
    " # Angle Filtration\n",
    "letter=np.full((10, 10), 100)\n",
    "\n",
    "# convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "for k in range(1,101):\n",
    "    if newLetter[k]==1.0:\n",
    "        row=int((k-1)/10) \n",
    "        column=(k-1)%10 \n",
    "        letter[row,column]=max(k%10,int(k-1)%10)            \n",
    "dgmNA = lower_star_img(letter)\n",
    "    \n",
    " # Diagonal Filtration\n",
    "letter=np.full((10, 10), 100)\n",
    "\n",
    "    # convert one line letter to 10x10 matrix replacing zeros with 100\n",
    "for k in range(1,101):\n",
    "    if newLetter[k]==1.0:\n",
    "        row=int((k-1)/10) \n",
    "        column=(k-1)%10 \n",
    "        letter[row,column]=(column+row)*k%10            \n",
    "dgmND = lower_star_img(letter)\n",
    "\n",
    "# A test to differentiate some letters\n",
    "\n",
    "bottom_test=sum(newLetter[51:101])\n",
    "    \n",
    "\n",
    "right_test=sum(np.concatenate((newLetter[6:11],\n",
    "              newLetter[16:21],\n",
    "              newLetter[26:31],\n",
    "              newLetter[36:41],\n",
    "              newLetter[46:51],\n",
    "              newLetter[56:61],\n",
    "              newLetter[66:71],\n",
    "              newLetter[76:81],\n",
    "              newLetter[86:91],\n",
    "              newLetter[96:101]\n",
    "              )))\n",
    "\n",
    "botright = sum(np.concatenate((\n",
    "              newLetter[56:61],\n",
    "              newLetter[66:71],\n",
    "              newLetter[76:81],\n",
    "              newLetter[86:91],\n",
    "              newLetter[96:101]\n",
    "              )))\n",
    "\n",
    "top_test = sum(newLetter[1:51])\n",
    "\n",
    "density_test = sum(newLetter[1:101])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the filtrations to find the bottleneck distance between the new letter and all of the old ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change infinities to very large numbers\n",
    "dgmNLR[np.isinf(dgmNLR)] = 10000\n",
    "dgmNRL[np.isinf(dgmNRL)] = 10000\n",
    "dgmNA[np.isinf(dgmNA)] = 10000\n",
    "dgmND[np.isinf(dgmND)] = 10000\n",
    "\n",
    "# Find bottleneck distance between new letter and previous letters\n",
    "\n",
    "# Left to Right\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "BNDNLR = [None]*26\n",
    "for i in range(26):\n",
    "    BNDNLR[i] = pm.bottleneck(dgmLR[i],dgmNLR)\n",
    "BNDNLR = np.array(BNDNLR)\n",
    "BNDNLR[BNDNLR>1000]=0\n",
    "\n",
    "# Right to Left\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "BNDNRL = [None]*26\n",
    "for i in range(26):\n",
    "    BNDNRL[i] = pm.bottleneck(dgmRL[i],dgmNRL)\n",
    "BNDNRL = np.array(BNDNRL) \n",
    "BNDNRL[BNDNRL>1000]=0\n",
    "\n",
    "# Angle\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "BNDNA = [None]*26\n",
    "for i in range(26):\n",
    "    BNDNA[i] = pm.bottleneck(dgmAngle[i],dgmNA)\n",
    "BNDNA = np.array(BNDNA)\n",
    "BNDNA[BNDNA>1000]=0\n",
    "    \n",
    "# Diagonoal\n",
    "# Calculate bottleneck distances and input into the pairwise matrix\n",
    "BNDND = [None]*26\n",
    "for i in range(26):\n",
    "    BNDND[i] = pm.bottleneck(dgmDiagonal[i],dgmND)\n",
    "BNDND = np.array(BNDND)\n",
    "BNDND[BNDND>1000]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert them into their values using Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left to Right Value\n",
    "temp=np.vstack((BNDLR,BNDNLR))\n",
    "temp2=np.append(BNDNLR,0)\n",
    "NewBNDLR = np.hstack((temp, np.atleast_2d(temp2).T))\n",
    "LRClust = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(NewBNDLR)\n",
    "LRValue=LRClust.labels_[26]\n",
    "\n",
    "# Right to Left Value\n",
    "temp=np.vstack((BNDRL,BNDNRL))\n",
    "temp2=np.append(BNDNRL,0)\n",
    "NewBNDRL = np.hstack((temp, np.atleast_2d(temp2).T))\n",
    "RLClust = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(NewBNDRL)\n",
    "RLValue=RLClust.labels_[26]\n",
    "\n",
    "\n",
    "# Angle Value\n",
    "temp=np.vstack((BNDAngle,BNDNA))\n",
    "temp2=np.append(BNDNA,0)\n",
    "NewBNDA = np.hstack((temp, np.atleast_2d(temp2).T))\n",
    "AngleClust = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(NewBNDA)\n",
    "AValue=AngleClust.labels_[26]\n",
    "\n",
    "\n",
    "# Diagonal Value\n",
    "temp=np.vstack((BNDDiagonal,BNDND))\n",
    "temp2=np.append(BNDND,0)\n",
    "NewBNDD = np.hstack((temp, np.atleast_2d(temp2).T))\n",
    "DiagonalClust = AgglomerativeClustering(n_clusters = 5,\n",
    "                                     affinity = \"precomputed\",\n",
    "                                     linkage = \"average\").fit(NewBNDD)\n",
    "DValue=DiagonalClust.labels_[26]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine these values into one vector and run our model on that vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_Letter = np.array((LRValue,\n",
    "                             RLValue,\n",
    "                             AValue,\n",
    "                             DValue,\n",
    "                             bottom_test,\n",
    "                             right_test,\n",
    "                             botright,\n",
    "                             top_test,\n",
    "                             density_test))\n",
    "LogReg.predict(New_Letter.reshape(1,-1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sparse Q is also classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
